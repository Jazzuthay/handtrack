<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/three/examples/js/loaders/GLTFLoader.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <style>
    body {
      margin: 0;
    }

    .container {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: calc(100vh * 9 / 16);
      height: 100vh;
      max-width: 100vw;
      max-height: 100vh;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .video-container {
      position: relative;
      width: 100%;
      height: 100%;
      overflow: hidden;
    }

    .input_video,
    .output_canvas,
    .three_canvas {
      position: absolute;
      top: 0;
      left: 50%;
      height: 100%;
      transform: translateX(-50%) scaleX(-1);
    }

    .input_video {
      width: auto;
      min-width: 100%;
    }

    .output_canvas,
    .three_canvas {
      width: 100%;
      height: auto;
    }

    .switch-camera-button {
      position: fixed;
      top: 20px;
      right: 20px;
      padding: 10px;
      background-color: #007bff;
      color: #fff;
      border: none;
      cursor: pointer;
    }
  </style>
</head>

<body>
  <div class="container">
    <div class="video-container">
      <video id="inputVideo" class="input_video" autoplay></video>
      <canvas class="output_canvas" width="720" height="1280"></canvas>
    </div>
    <canvas id="three_canvas" class="three_canvas" width="720" height="1280"></canvas>
  </div>
  <button id="switchCameraButton" class="switch-camera-button">Switch Camera</button>
  <script>
    let aspectRatio = 9 / 16;

    // Initialize Three.js
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(33, aspectRatio, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('three_canvas'), alpha: true });
    renderer.setSize(720, 1280);
    camera.position.z = 2;

    // Ambient light
    const ambientLight = new THREE.AmbientLight(0xffffff, 5); // Soft white light
    scene.add(ambientLight);

    // Directional light
    const directionalLight = new THREE.DirectionalLight(0xffffff, 5);
    directionalLight.position.set(1, 1, 1).normalize();
    scene.add(directionalLight);

    let model;
    const loader = new THREE.GLTFLoader();
    loader.load('watch1.glb', function (gltf) {
      model = gltf.scene;

      model.rotation.set(0, 0, Math.PI / 2);
      model.scale.set(0.3, 0.3, 0.2);

      scene.add(model);

      //console.log('Model loaded');
    });

    function animate() {
      requestAnimationFrame(animate);
      renderer.render(scene, camera);
    }
    animate();

    // MediaPipe setup
    const videoElement = document.getElementById('inputVideo');
    const canvasElement = document.getElementsByClassName('output_canvas')[0];
    const canvasCtx = canvasElement.getContext('2d');
    
    //scale limit and time
    const minScale = 0.4;
    const maxScale = 0.5;
    let lastUpdateTime = 0;
    const scaleTransitionDuration = 200;

    function updateModelPosition(firstHandLandmarks) {
      if (firstHandLandmarks.length > 0) {
        const firstLandmark = firstHandLandmarks[0];
        const wristLandmark = firstHandLandmarks[0];
        const middleFingerBase = firstHandLandmarks[9];
        // console.log('Model Beforupdate:', firstHandLandmarks[0].position);

         //taking rotaion values from landmark
        const dx = middleFingerBase.x - wristLandmark.x;
        const dy = middleFingerBase.y - wristLandmark.y;
        const angle = -Math.atan2(dy, dx);

        //assign Postion for 3d model
        const scaleFactor = 1.05;
        const normalizedX = firstLandmark.x;
        const normalizedY = firstLandmark.y;
        const normalizedZ = firstLandmark.z;

        const modelPosition = new THREE.Vector3(
          (normalizedX * scaleFactor - 0.55),
          -normalizedY * (1.7) + 1.3,
          -(normalizedZ * scaleFactor + 3)
        );
        
        //scaling
        const scaleValue = (firstLandmark.z * (10 ** 6))* 1.2;
        const clampedScaleValue = THREE.MathUtils.clamp(scaleValue, minScale, maxScale);

        const currentTime = Date.now();
        const deltaTime = currentTime - lastUpdateTime;
        const t = THREE.MathUtils.clamp(deltaTime / scaleTransitionDuration, 0, 1);

        const currentScale = model.scale.x;
        const targetScale = clampedScaleValue - 0.05;
        const interpolatedScale = THREE.MathUtils.lerp(currentScale, targetScale, t);

        if (model) {
          model.position.copy(modelPosition);
          model.rotation.z = angle;
          model.scale.set(interpolatedScale, interpolatedScale, 0.1);
          //console.log('Model updated:', model.position, model.rotation, model.scale);
        }

        lastUpdateTime = currentTime;
      }
    }

    function onResults(results) {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      const videoWidth = videoElement.videoWidth;
      const videoHeight = videoElement.videoHeight;
      const aspectRatio = videoWidth / videoHeight;
      const targetAspectRatio = 9 / 16;
      let sx, sy, sw, sh;

      if (aspectRatio > targetAspectRatio) {
        sw = videoHeight * targetAspectRatio;
        sh = videoHeight;
        sx = (videoWidth - sw) / 2;
        sy = 0;
      } else {
        sw = videoWidth;
        sh = videoWidth / targetAspectRatio;
        sx = 0;
        sy = (videoHeight - sh) / 2;
      }

      canvasCtx.drawImage(videoElement, sx, sy, sw, sh, 0, 0, canvasElement.width, canvasElement.height);

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const firstHandLandmarks = results.multiHandLandmarks[0];

        updateModelPosition(firstHandLandmarks);

        drawConnectors(canvasCtx, firstHandLandmarks, HAND_CONNECTIONS, { color: '#FFFFFF', lineWidth: 5 });
        drawLandmarks(canvasCtx, firstHandLandmarks, { color: '#0000FF', lineWidth: 2 });
      }

      canvasCtx.restore();
    }

    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    //mediapipe setting options
    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.6,
    });

    hands.onResults((results) => {
      console.log('MediaPipe results:', results);
      onResults(results);
    });

    //camera input feed
    const cameraFeed = new Camera(videoElement, {
      onFrame: async () => {
        const videoWidth = videoElement.videoWidth;
        const videoHeight = videoElement.videoHeight;
        const aspectRatio = videoWidth / videoHeight;
        const targetAspectRatio = 9 / 16;
        let sx, sy, sw, sh;

        if (aspectRatio > targetAspectRatio) {
          sw = videoHeight * targetAspectRatio;
          sh = videoHeight;
          sx = (videoWidth - sw) / 2;
          sy = 0;
        } else {
          sw = videoWidth;
          sh = videoWidth / targetAspectRatio;
          sx = 0;
          sy = (videoHeight - sh) / 2;
        }

        const croppedVideoFrame = document.createElement('canvas');
        croppedVideoFrame.width = sw;
        croppedVideoFrame.height = sh;
        const ctx = croppedVideoFrame.getContext('2d');
        ctx.drawImage(videoElement, sx, sy, sw, sh, 0, 0, sw, sh);

        await hands.send({ image: croppedVideoFrame });
      },
      width: 1280,
      height: 720,
    });

    cameraFeed.start();

    // switch camera
    const switchCameraButton = document.getElementById('switchCameraButton');
    let facingMode = 'user';

    switchCameraButton.addEventListener('click', async () => {
      facingMode = facingMode === 'user' ? 'environment' : 'user';

      const constraints = {
        video: { facingMode: facingMode },
      };

      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        videoElement.srcObject = stream;
      } catch (error) {
        console.error('Error accessing the camera:', error);
      }
    });

  
    window.addEventListener('resize', () => {
      const width = window.innerWidth;
      const height = width * aspectRatio;
      renderer.setSize(width, height);
      camera.aspect = width / height;
      camera.updateProjectionMatrix();
      console.log('Window resized:', width, height);
    });
  </script>
</body>

</html>
